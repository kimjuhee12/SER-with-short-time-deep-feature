{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conv1D layer -> LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from emotion_recognition import utils\n",
    "from emotion_recognition import features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "time_step = 32\n",
    "window_size = 1000\n",
    "overlap_facor = 3\n",
    "class_size = 4\n",
    "feature_size = 160\n",
    "frame_size = 500 # 음성구간 찾기 위한 프레임 크기 \n",
    "\n",
    "# 0 = neutral, 1 = anger, 2 = happiness, 3 = sadness\n",
    "emotion = [\"neutral\",\"anger\",\"happiness\",\"sadness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading filelist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 이름 읽어오기\n",
    "path = \"../data/\"\n",
    "text_filename = \"filelist_wav.txt\"\n",
    "\n",
    "filelist_wav = []\n",
    "emotionlist = []\n",
    "\n",
    "f = open(path+text_filename, 'r')\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    \n",
    "    filename, label = line.split()\n",
    "    \n",
    "    filelist_wav.append(filename)\n",
    "    emotionlist.append(label)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting the data into trainnnig and test\n",
    "- For test, subjects 1,6,7,11 \n",
    "- For training, subjects 2,3,4,5,8,9,10,12,13,14,15,16,17,18,19,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_filename = []\n",
    "Training_emotionlist = []\n",
    "Test_filename = []\n",
    "Test_emotionlist = []\n",
    "\n",
    "for i in range(len(filelist_wav)):\n",
    "    if (filelist_wav[i].split(\"_\")[0][1:] == '1'):\n",
    "        Test_filename.append(filelist_wav[i])\n",
    "        Test_emotionlist.append(emotionlist[i])\n",
    "    elif (filelist_wav[i].split(\"_\")[0][1:] == '6'):\n",
    "        Test_filename.append(filelist_wav[i])\n",
    "        Test_emotionlist.append(emotionlist[i])\n",
    "    elif (filelist_wav[i].split(\"_\")[0][1:] == '7'):\n",
    "        Test_filename.append(filelist_wav[i])\n",
    "        Test_emotionlist.append(emotionlist[i])\n",
    "    elif (filelist_wav[i].split(\"_\")[0][1:] == '11'):\n",
    "        Test_filename.append(filelist_wav[i])\n",
    "        Test_emotionlist.append(emotionlist[i])\n",
    "    else:\n",
    "        Training_filename.append(filelist_wav[i])\n",
    "        Training_emotionlist.append(emotionlist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614,)\n",
      "(226,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(Training_filename))\n",
    "print (np.shape(Test_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Speech data segmentation without unvoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tsadness\t../data/wav/s19_sadness_M_s17.wav\n",
      "1\tsadness\t../data/wav/s18_sadness_F_s1.wav\n",
      "4\tanger\t../data/wav/s15_anger_F_a11.wav\n",
      "6\tsadness\t../data/wav/s19_sadness_M_s8.wav\n",
      "8\tneutral\t../data/wav/s18_neutral_F_n14.wav\n",
      "9\tsadness\t../data/wav/s20_sadness_F_s20.wav\n",
      "11\thappiness\t../data/wav/s3_happiness_M_h10.wav\n",
      "13\thappiness\t../data/wav/s5_happiness_M_h8.wav\n",
      "14\tsadness\t../data/wav/s8_sadness_M_s17.wav\n",
      "15\thappiness\t../data/wav/s5_happiness_M_h16.wav\n",
      "16\thappiness\t../data/wav/s4_happiness_M_h10.wav\n",
      "17\tneutral\t../data/wav/s9_neutral_M_n10.wav\n",
      "20\tanger\t../data/wav/s19_anger_M_a18.wav\n",
      "21\tneutral\t../data/wav/s15_neutral_F_n11.wav\n",
      "22\tanger\t../data/wav/s14_anger_M_a17.wav\n",
      "23\tneutral\t../data/wav/s12_neutral_F_n5.wav\n",
      "24\tneutral\t../data/wav/s15_neutral_F_n16.wav\n",
      "25\thappiness\t../data/wav/s19_happiness_M_h7.wav\n",
      "28\thappiness\t../data/wav/s10_happiness_M_h10.wav\n",
      "29\thappiness\t../data/wav/s20_happiness_F_h8.wav\n",
      "30\thappiness\t../data/wav/s19_happiness_M_h8.wav\n",
      "31\tsadness\t../data/wav/s12_sadness_F_s12.wav\n",
      "32\tneutral\t../data/wav/s20_neutral_F_n20.wav\n",
      "33\tanger\t../data/wav/s15_anger_F_a9.wav\n",
      "34\tsadness\t../data/wav/s19_sadness_M_s5.wav\n",
      "35\tsadness\t../data/wav/s9_sadness_M_s8.wav\n",
      "36\tanger\t../data/wav/s13_anger_F_a9.wav\n",
      "37\tneutral\t../data/wav/s8_neutral_M_n14.wav\n",
      "38\tneutral\t../data/wav/s2_neutral_M_n16.wav\n",
      "39\tneutral\t../data/wav/s19_neutral_M_n12.wav\n",
      "40\tsadness\t../data/wav/s18_sadness_F_s9.wav\n",
      "41\tneutral\t../data/wav/s12_neutral_F_n3.wav\n",
      "42\tsadness\t../data/wav/s2_sadness_M_s15.wav\n",
      "43\tsadness\t../data/wav/s18_sadness_F_s14.wav\n",
      "44\tanger\t../data/wav/s5_anger_M_a20.wav\n",
      "45\tsadness\t../data/wav/s10_sadness_M_s5.wav\n",
      "46\tanger\t../data/wav/s19_anger_M_a15.wav\n",
      "48\tneutral\t../data/wav/s12_neutral_F_n17.wav\n",
      "49\thappiness\t../data/wav/s14_happiness_M_h18.wav\n",
      "52\tanger\t../data/wav/s15_anger_F_a12.wav\n",
      "55\tneutral\t../data/wav/s4_neutral_M_n19.wav\n",
      "56\thappiness\t../data/wav/s3_happiness_M_h11.wav\n",
      "58\tneutral\t../data/wav/s18_neutral_F_n11.wav\n",
      "60\tsadness\t../data/wav/s18_sadness_F_s3.wav\n",
      "61\tneutral\t../data/wav/s19_neutral_M_n4.wav\n",
      "62\thappiness\t../data/wav/s3_happiness_M_h8.wav\n",
      "63\tanger\t../data/wav/s2_anger_M_a5.wav\n",
      "64\tneutral\t../data/wav/s12_neutral_F_n9.wav\n",
      "65\tneutral\t../data/wav/s15_neutral_F_n4.wav\n",
      "66\tneutral\t../data/wav/s18_neutral_F_n7.wav\n",
      "68\thappiness\t../data/wav/s19_happiness_M_h14.wav\n",
      "70\thappiness\t../data/wav/s18_happiness_F_h4.wav\n",
      "71\tanger\t../data/wav/s5_anger_M_a6.wav\n",
      "72\tneutral\t../data/wav/s12_neutral_F_n15.wav\n",
      "74\tanger\t../data/wav/s20_anger_F_a7.wav\n",
      "76\thappiness\t../data/wav/s13_happiness_F_h2.wav\n",
      "77\tsadness\t../data/wav/s13_sadness_F_s6.wav\n",
      "79\tneutral\t../data/wav/s15_neutral_F_n14.wav\n",
      "80\thappiness\t../data/wav/s18_happiness_F_h1.wav\n",
      "81\tsadness\t../data/wav/s20_sadness_F_s9.wav\n",
      "82\tanger\t../data/wav/s19_anger_M_a20.wav\n",
      "85\tneutral\t../data/wav/s19_neutral_M_n5.wav\n",
      "86\tanger\t../data/wav/s3_anger_M_a15.wav\n",
      "88\tneutral\t../data/wav/s2_neutral_M_n5.wav\n",
      "89\tsadness\t../data/wav/s10_sadness_M_s2.wav\n",
      "91\tanger\t../data/wav/s12_anger_F_a7.wav\n",
      "96\thappiness\t../data/wav/s19_happiness_M_h2.wav\n",
      "98\tanger\t../data/wav/s5_anger_M_a14.wav\n",
      "100\tsadness\t../data/wav/s9_sadness_M_s11.wav\n",
      "101\tneutral\t../data/wav/s2_neutral_M_n15.wav\n",
      "102\tanger\t../data/wav/s15_anger_F_a3.wav\n",
      "105\tsadness\t../data/wav/s9_sadness_M_s10.wav\n",
      "106\tsadness\t../data/wav/s18_sadness_F_s16.wav\n",
      "109\tneutral\t../data/wav/s15_neutral_F_n6.wav\n",
      "113\tneutral\t../data/wav/s18_neutral_F_n5.wav\n",
      "114\tneutral\t../data/wav/s2_neutral_M_n8.wav\n",
      "117\thappiness\t../data/wav/s19_happiness_M_h1.wav\n",
      "118\thappiness\t../data/wav/s13_happiness_F_h3.wav\n",
      "120\tsadness\t../data/wav/s10_sadness_M_s15.wav\n",
      "121\thappiness\t../data/wav/s3_happiness_M_h12.wav\n",
      "122\tneutral\t../data/wav/s18_neutral_F_n10.wav\n",
      "124\tsadness\t../data/wav/s9_sadness_M_s5.wav\n",
      "125\tanger\t../data/wav/s18_anger_F_a10.wav\n",
      "127\thappiness\t../data/wav/s4_happiness_M_h18.wav\n",
      "129\tsadness\t../data/wav/s2_sadness_M_s17.wav\n",
      "130\thappiness\t../data/wav/s18_happiness_F_h13.wav\n",
      "131\tsadness\t../data/wav/s10_sadness_M_s20.wav\n",
      "132\tsadness\t../data/wav/s20_sadness_F_s4.wav\n",
      "133\tanger\t../data/wav/s9_anger_M_a1.wav\n",
      "134\thappiness\t../data/wav/s3_happiness_M_h14.wav\n",
      "136\tanger\t../data/wav/s5_anger_M_a7.wav\n",
      "139\tanger\t../data/wav/s12_anger_F_a16.wav\n",
      "140\tanger\t../data/wav/s19_anger_M_a11.wav\n",
      "141\tanger\t../data/wav/s9_anger_M_a7.wav\n",
      "143\thappiness\t../data/wav/s15_happiness_F_h15.wav\n",
      "146\tanger\t../data/wav/s18_anger_F_a17.wav\n",
      "149\tneutral\t../data/wav/s13_neutral_F_n19.wav\n",
      "150\tanger\t../data/wav/s5_anger_M_a18.wav\n",
      "151\tneutral\t../data/wav/s13_neutral_F_n20.wav\n",
      "152\tanger\t../data/wav/s18_anger_F_a15.wav\n",
      "153\tneutral\t../data/wav/s8_neutral_M_n4.wav\n",
      "156\tsadness\t../data/wav/s2_sadness_M_s16.wav\n",
      "157\thappiness\t../data/wav/s3_happiness_M_h18.wav\n",
      "158\thappiness\t../data/wav/s15_happiness_F_h17.wav\n",
      "159\thappiness\t../data/wav/s15_happiness_F_h14.wav\n",
      "161\thappiness\t../data/wav/s4_happiness_M_h14.wav\n",
      "162\tsadness\t../data/wav/s9_sadness_M_s13.wav\n",
      "163\tneutral\t../data/wav/s20_neutral_F_n5.wav\n",
      "164\thappiness\t../data/wav/s3_happiness_M_h2.wav\n",
      "165\tsadness\t../data/wav/s14_sadness_M_s9.wav\n",
      "168\tsadness\t../data/wav/s2_sadness_M_s20.wav\n",
      "169\thappiness\t../data/wav/s19_happiness_M_h13.wav\n",
      "170\thappiness\t../data/wav/s10_happiness_M_h5.wav\n",
      "171\tanger\t../data/wav/s19_anger_M_a13.wav\n",
      "172\tneutral\t../data/wav/s12_neutral_F_n20.wav\n",
      "175\tanger\t../data/wav/s9_anger_M_a8.wav\n",
      "177\tsadness\t../data/wav/s5_sadness_M_s19.wav\n",
      "179\tneutral\t../data/wav/s8_neutral_M_n13.wav\n",
      "180\tanger\t../data/wav/s2_anger_M_a8.wav\n",
      "181\tsadness\t../data/wav/s5_sadness_M_s1.wav\n",
      "182\thappiness\t../data/wav/s13_happiness_F_h10.wav\n",
      "184\tanger\t../data/wav/s12_anger_F_a17.wav\n",
      "185\tsadness\t../data/wav/s18_sadness_F_s4.wav\n",
      "186\tneutral\t../data/wav/s2_neutral_M_n20.wav\n",
      "187\tanger\t../data/wav/s12_anger_F_a8.wav\n",
      "188\tneutral\t../data/wav/s9_neutral_M_n14.wav\n",
      "189\tneutral\t../data/wav/s15_neutral_F_n12.wav\n",
      "191\thappiness\t../data/wav/s4_happiness_M_h12.wav\n",
      "192\thappiness\t../data/wav/s18_happiness_F_h14.wav\n",
      "193\tneutral\t../data/wav/s2_neutral_M_n12.wav\n",
      "196\tsadness\t../data/wav/s19_sadness_M_s18.wav\n",
      "197\thappiness\t../data/wav/s19_happiness_M_h4.wav\n",
      "198\tsadness\t../data/wav/s20_sadness_F_s14.wav\n",
      "199\tanger\t../data/wav/s19_anger_M_a12.wav\n",
      "200\thappiness\t../data/wav/s10_happiness_M_h16.wav\n",
      "202\tneutral\t../data/wav/s19_neutral_M_n17.wav\n",
      "205\tneutral\t../data/wav/s12_neutral_F_n13.wav\n",
      "206\tanger\t../data/wav/s10_anger_M_a6.wav\n",
      "209\thappiness\t../data/wav/s18_happiness_F_h8.wav\n",
      "210\tneutral\t../data/wav/s8_neutral_M_n18.wav\n",
      "212\tsadness\t../data/wav/s13_sadness_F_s13.wav\n",
      "215\thappiness\t../data/wav/s3_happiness_M_h16.wav\n",
      "217\tneutral\t../data/wav/s9_neutral_M_n16.wav\n",
      "219\tsadness\t../data/wav/s19_sadness_M_s3.wav\n",
      "220\tneutral\t../data/wav/s20_neutral_F_n8.wav\n",
      "221\tanger\t../data/wav/s20_anger_F_a19.wav\n",
      "223\tsadness\t../data/wav/s12_sadness_F_s4.wav\n",
      "224\thappiness\t../data/wav/s9_happiness_M_h15.wav\n",
      "225\tneutral\t../data/wav/s15_neutral_F_n5.wav\n",
      "226\tanger\t../data/wav/s15_anger_F_a10.wav\n",
      "227\tsadness\t../data/wav/s10_sadness_M_s9.wav\n",
      "229\tsadness\t../data/wav/s9_sadness_M_s14.wav\n",
      "230\tneutral\t../data/wav/s2_neutral_M_n18.wav\n",
      "231\tanger\t../data/wav/s12_anger_F_a14.wav\n",
      "232\tanger\t../data/wav/s12_anger_F_a4.wav\n",
      "234\thappiness\t../data/wav/s13_happiness_F_h14.wav\n",
      "236\thappiness\t../data/wav/s10_happiness_M_h13.wav\n",
      "238\thappiness\t../data/wav/s15_happiness_F_h12.wav\n",
      "241\tanger\t../data/wav/s15_anger_F_a19.wav\n",
      "245\tneutral\t../data/wav/s15_neutral_F_n13.wav\n",
      "247\tanger\t../data/wav/s9_anger_M_a4.wav\n",
      "249\tanger\t../data/wav/s14_anger_M_a7.wav\n",
      "250\thappiness\t../data/wav/s10_happiness_M_h15.wav\n",
      "251\tneutral\t../data/wav/s15_neutral_F_n17.wav\n",
      "252\thappiness\t../data/wav/s18_happiness_F_h3.wav\n",
      "253\tsadness\t../data/wav/s2_sadness_M_s8.wav\n",
      "255\tanger\t../data/wav/s5_anger_M_a15.wav\n",
      "257\thappiness\t../data/wav/s13_happiness_F_h16.wav\n",
      "259\tanger\t../data/wav/s5_anger_M_a19.wav\n",
      "262\tsadness\t../data/wav/s14_sadness_M_s13.wav\n",
      "263\thappiness\t../data/wav/s9_happiness_M_h12.wav\n",
      "264\tsadness\t../data/wav/s15_sadness_F_s18.wav\n",
      "265\tanger\t../data/wav/s15_anger_F_a13.wav\n",
      "266\thappiness\t../data/wav/s19_happiness_M_h12.wav\n",
      "267\tneutral\t../data/wav/s13_neutral_F_n1.wav\n",
      "268\tanger\t../data/wav/s20_anger_F_a15.wav\n",
      "269\tneutral\t../data/wav/s18_neutral_F_n1.wav\n",
      "271\tanger\t../data/wav/s9_anger_M_a10.wav\n",
      "273\tanger\t../data/wav/s15_anger_F_a20.wav\n",
      "274\tneutral\t../data/wav/s13_neutral_F_n8.wav\n",
      "275\tsadness\t../data/wav/s15_sadness_F_s10.wav\n",
      "276\tsadness\t../data/wav/s10_sadness_M_s4.wav\n",
      "278\thappiness\t../data/wav/s20_happiness_F_h10.wav\n",
      "279\thappiness\t../data/wav/s19_happiness_M_h10.wav\n",
      "281\tsadness\t../data/wav/s18_sadness_F_s13.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\thappiness\t../data/wav/s19_happiness_M_h9.wav\n",
      "284\tneutral\t../data/wav/s9_neutral_M_n13.wav\n",
      "285\thappiness\t../data/wav/s12_happiness_F_h4.wav\n",
      "287\tanger\t../data/wav/s13_anger_F_a12.wav\n",
      "288\thappiness\t../data/wav/s10_happiness_M_h14.wav\n",
      "289\thappiness\t../data/wav/s2_happiness_M_h18.wav\n",
      "290\tneutral\t../data/wav/s19_neutral_M_n13.wav\n",
      "291\tneutral\t../data/wav/s13_neutral_F_n13.wav\n",
      "292\tsadness\t../data/wav/s15_sadness_F_s5.wav\n",
      "294\tanger\t../data/wav/s5_anger_M_a8.wav\n",
      "296\tsadness\t../data/wav/s4_sadness_M_s18.wav\n",
      "298\tsadness\t../data/wav/s4_sadness_M_s17.wav\n",
      "299\tsadness\t../data/wav/s9_sadness_M_s1.wav\n",
      "301\tsadness\t../data/wav/s10_sadness_M_s12.wav\n",
      "302\thappiness\t../data/wav/s8_happiness_M_h5.wav\n",
      "303\tanger\t../data/wav/s15_anger_F_a17.wav\n",
      "304\tneutral\t../data/wav/s12_neutral_F_n12.wav\n",
      "305\tsadness\t../data/wav/s15_sadness_F_s15.wav\n",
      "306\tanger\t../data/wav/s15_anger_F_a16.wav\n",
      "307\tneutral\t../data/wav/s14_neutral_M_n20.wav\n",
      "308\tneutral\t../data/wav/s14_neutral_M_n13.wav\n",
      "311\tneutral\t../data/wav/s9_neutral_M_n2.wav\n",
      "312\tneutral\t../data/wav/s3_neutral_M_n13.wav\n",
      "313\tneutral\t../data/wav/s2_neutral_M_n14.wav\n",
      "315\tsadness\t../data/wav/s18_sadness_F_s8.wav\n",
      "316\tneutral\t../data/wav/s18_neutral_F_n19.wav\n",
      "319\tneutral\t../data/wav/s8_neutral_M_n8.wav\n",
      "320\tneutral\t../data/wav/s3_neutral_M_n5.wav\n",
      "321\tneutral\t../data/wav/s13_neutral_F_n12.wav\n",
      "324\tanger\t../data/wav/s3_anger_M_a9.wav\n",
      "326\thappiness\t../data/wav/s15_happiness_F_h16.wav\n",
      "327\tneutral\t../data/wav/s12_neutral_F_n18.wav\n",
      "328\tneutral\t../data/wav/s19_neutral_M_n20.wav\n",
      "329\tanger\t../data/wav/s12_anger_F_a13.wav\n",
      "331\tsadness\t../data/wav/s18_sadness_F_s15.wav\n",
      "332\thappiness\t../data/wav/s15_happiness_F_h10.wav\n",
      "333\tneutral\t../data/wav/s19_neutral_M_n11.wav\n",
      "334\tsadness\t../data/wav/s20_sadness_F_s13.wav\n",
      "336\tneutral\t../data/wav/s15_neutral_F_n8.wav\n",
      "337\thappiness\t../data/wav/s3_happiness_M_h6.wav\n",
      "340\thappiness\t../data/wav/s13_happiness_F_h19.wav\n",
      "341\tanger\t../data/wav/s13_anger_F_a4.wav\n",
      "343\tanger\t../data/wav/s9_anger_M_a17.wav\n",
      "344\thappiness\t../data/wav/s18_happiness_F_h15.wav\n",
      "347\thappiness\t../data/wav/s19_happiness_M_h5.wav\n",
      "348\tsadness\t../data/wav/s20_sadness_F_s5.wav\n",
      "351\tsadness\t../data/wav/s14_sadness_M_s10.wav\n",
      "352\tneutral\t../data/wav/s15_neutral_F_n15.wav\n",
      "353\thappiness\t../data/wav/s19_happiness_M_h15.wav\n",
      "355\tneutral\t../data/wav/s9_neutral_M_n17.wav\n",
      "356\tanger\t../data/wav/s12_anger_F_a20.wav\n",
      "357\thappiness\t../data/wav/s10_happiness_M_h8.wav\n",
      "360\tanger\t../data/wav/s19_anger_M_a2.wav\n",
      "362\thappiness\t../data/wav/s3_happiness_M_h19.wav\n",
      "363\tsadness\t../data/wav/s19_sadness_M_s6.wav\n",
      "364\thappiness\t../data/wav/s16_happiness_M_h11.wav\n",
      "365\tsadness\t../data/wav/s14_sadness_M_s18.wav\n",
      "370\thappiness\t../data/wav/s5_happiness_M_h14.wav\n",
      "371\tsadness\t../data/wav/s10_sadness_M_s7.wav\n",
      "372\tneutral\t../data/wav/s3_neutral_M_n14.wav\n",
      "373\tneutral\t../data/wav/s8_neutral_M_n5.wav\n",
      "374\tneutral\t../data/wav/s9_neutral_M_n9.wav\n",
      "376\thappiness\t../data/wav/s13_happiness_F_h7.wav\n",
      "377\tsadness\t../data/wav/s14_sadness_M_s7.wav\n",
      "378\tanger\t../data/wav/s15_anger_F_a6.wav\n",
      "381\thappiness\t../data/wav/s4_happiness_M_h2.wav\n",
      "382\tneutral\t../data/wav/s19_neutral_M_n15.wav\n",
      "384\tneutral\t../data/wav/s12_neutral_F_n14.wav\n",
      "385\thappiness\t../data/wav/s4_happiness_M_h5.wav\n",
      "386\tneutral\t../data/wav/s2_neutral_M_n17.wav\n",
      "388\thappiness\t../data/wav/s12_happiness_F_h11.wav\n",
      "389\tneutral\t../data/wav/s15_neutral_F_n7.wav\n",
      "390\tneutral\t../data/wav/s18_neutral_F_n17.wav\n",
      "392\thappiness\t../data/wav/s10_happiness_M_h9.wav\n",
      "393\tneutral\t../data/wav/s15_neutral_F_n10.wav\n",
      "394\tsadness\t../data/wav/s18_sadness_F_s19.wav\n",
      "395\tsadness\t../data/wav/s12_sadness_F_s17.wav\n",
      "396\tanger\t../data/wav/s5_anger_M_a17.wav\n",
      "397\tsadness\t../data/wav/s12_sadness_F_s7.wav\n",
      "399\thappiness\t../data/wav/s15_happiness_F_h20.wav\n",
      "400\thappiness\t../data/wav/s4_happiness_M_h20.wav\n",
      "402\thappiness\t../data/wav/s3_happiness_M_h13.wav\n",
      "403\tneutral\t../data/wav/s18_neutral_F_n8.wav\n",
      "404\tneutral\t../data/wav/s3_neutral_M_n7.wav\n",
      "405\tneutral\t../data/wav/s18_neutral_F_n15.wav\n",
      "408\tsadness\t../data/wav/s13_sadness_F_s11.wav\n",
      "409\tanger\t../data/wav/s5_anger_M_a13.wav\n",
      "410\tanger\t../data/wav/s5_anger_M_a10.wav\n",
      "412\thappiness\t../data/wav/s10_happiness_M_h12.wav\n",
      "413\thappiness\t../data/wav/s18_happiness_F_h10.wav\n",
      "414\tneutral\t../data/wav/s12_neutral_F_n16.wav\n",
      "415\tsadness\t../data/wav/s2_sadness_M_s6.wav\n",
      "419\tsadness\t../data/wav/s10_sadness_M_s18.wav\n",
      "422\tsadness\t../data/wav/s13_sadness_F_s20.wav\n",
      "423\thappiness\t../data/wav/s15_happiness_F_h7.wav\n",
      "424\tanger\t../data/wav/s14_anger_M_a20.wav\n",
      "426\tsadness\t../data/wav/s4_sadness_M_s13.wav\n",
      "427\tanger\t../data/wav/s12_anger_F_a9.wav\n",
      "428\tneutral\t../data/wav/s9_neutral_M_n8.wav\n",
      "430\tneutral\t../data/wav/s12_neutral_F_n7.wav\n",
      "431\thappiness\t../data/wav/s20_happiness_F_h18.wav\n",
      "432\thappiness\t../data/wav/s18_happiness_F_h2.wav\n",
      "433\tanger\t../data/wav/s5_anger_M_a11.wav\n",
      "434\tanger\t../data/wav/s13_anger_F_a17.wav\n",
      "435\tanger\t../data/wav/s5_anger_M_a9.wav\n",
      "436\tneutral\t../data/wav/s19_neutral_M_n19.wav\n",
      "437\tsadness\t../data/wav/s10_sadness_M_s10.wav\n",
      "439\tanger\t../data/wav/s2_anger_M_a7.wav\n",
      "440\thappiness\t../data/wav/s17_happiness_M_h2.wav\n",
      "443\tneutral\t../data/wav/s18_neutral_F_n6.wav\n",
      "444\tneutral\t../data/wav/s12_neutral_F_n10.wav\n",
      "446\thappiness\t../data/wav/s15_happiness_F_h11.wav\n",
      "447\tneutral\t../data/wav/s19_neutral_M_n8.wav\n",
      "450\tneutral\t../data/wav/s8_neutral_M_n7.wav\n",
      "453\thappiness\t../data/wav/s20_happiness_F_h15.wav\n",
      "454\thappiness\t../data/wav/s9_happiness_M_h10.wav\n",
      "455\tsadness\t../data/wav/s2_sadness_M_s4.wav\n",
      "456\thappiness\t../data/wav/s20_happiness_F_h16.wav\n",
      "458\tneutral\t../data/wav/s9_neutral_M_n12.wav\n",
      "463\tanger\t../data/wav/s19_anger_M_a17.wav\n",
      "464\tsadness\t../data/wav/s18_sadness_F_s5.wav\n",
      "468\tsadness\t../data/wav/s15_sadness_F_s14.wav\n",
      "469\tanger\t../data/wav/s5_anger_M_a5.wav\n",
      "470\tsadness\t../data/wav/s20_sadness_F_s7.wav\n",
      "471\tsadness\t../data/wav/s17_sadness_M_s12.wav\n",
      "472\tanger\t../data/wav/s15_anger_F_a8.wav\n",
      "473\tsadness\t../data/wav/s20_sadness_F_s16.wav\n",
      "474\tneutral\t../data/wav/s12_neutral_F_n6.wav\n",
      "476\tneutral\t../data/wav/s18_neutral_F_n4.wav\n",
      "480\thappiness\t../data/wav/s3_happiness_M_h4.wav\n",
      "481\tanger\t../data/wav/s12_anger_F_a10.wav\n",
      "482\tanger\t../data/wav/s12_anger_F_a19.wav\n",
      "484\tanger\t../data/wav/s5_anger_M_a4.wav\n",
      "485\tneutral\t../data/wav/s9_neutral_M_n19.wav\n",
      "488\tanger\t../data/wav/s3_anger_M_a19.wav\n",
      "489\tanger\t../data/wav/s10_anger_M_a17.wav\n",
      "491\tsadness\t../data/wav/s20_sadness_F_s3.wav\n",
      "492\thappiness\t../data/wav/s3_happiness_M_h5.wav\n",
      "493\tanger\t../data/wav/s13_anger_F_a14.wav\n",
      "494\tsadness\t../data/wav/s12_sadness_F_s9.wav\n",
      "495\tneutral\t../data/wav/s9_neutral_M_n20.wav\n",
      "496\tsadness\t../data/wav/s14_sadness_M_s17.wav\n",
      "498\tanger\t../data/wav/s17_anger_M_a17.wav\n",
      "499\tanger\t../data/wav/s9_anger_M_a18.wav\n",
      "500\tanger\t../data/wav/s18_anger_F_a19.wav\n",
      "501\tanger\t../data/wav/s19_anger_M_a16.wav\n",
      "503\tneutral\t../data/wav/s18_neutral_F_n16.wav\n",
      "504\tanger\t../data/wav/s13_anger_F_a13.wav\n",
      "505\tanger\t../data/wav/s15_anger_F_a15.wav\n",
      "506\tsadness\t../data/wav/s12_sadness_F_s6.wav\n",
      "507\thappiness\t../data/wav/s19_happiness_M_h11.wav\n",
      "509\tneutral\t../data/wav/s3_neutral_M_n11.wav\n",
      "510\thappiness\t../data/wav/s3_happiness_M_h7.wav\n",
      "511\tneutral\t../data/wav/s8_neutral_M_n17.wav\n",
      "513\tneutral\t../data/wav/s19_neutral_M_n1.wav\n",
      "516\tsadness\t../data/wav/s20_sadness_F_s17.wav\n",
      "517\tneutral\t../data/wav/s12_neutral_F_n11.wav\n",
      "521\thappiness\t../data/wav/s13_happiness_F_h6.wav\n",
      "522\thappiness\t../data/wav/s9_happiness_M_h18.wav\n",
      "524\tsadness\t../data/wav/s2_sadness_M_s10.wav\n",
      "525\thappiness\t../data/wav/s4_happiness_M_h8.wav\n",
      "527\tneutral\t../data/wav/s19_neutral_M_n2.wav\n",
      "528\tsadness\t../data/wav/s20_sadness_F_s12.wav\n",
      "529\tneutral\t../data/wav/s12_neutral_F_n4.wav\n",
      "530\tneutral\t../data/wav/s19_neutral_M_n14.wav\n",
      "531\tsadness\t../data/wav/s12_sadness_F_s5.wav\n",
      "535\thappiness\t../data/wav/s18_happiness_F_h12.wav\n",
      "536\tsadness\t../data/wav/s15_sadness_F_s17.wav\n",
      "538\tneutral\t../data/wav/s19_neutral_M_n16.wav\n",
      "539\thappiness\t../data/wav/s18_happiness_F_h11.wav\n",
      "540\tsadness\t../data/wav/s9_sadness_M_s9.wav\n",
      "541\tsadness\t../data/wav/s9_sadness_M_s17.wav\n",
      "544\tanger\t../data/wav/s18_anger_F_a20.wav\n",
      "545\tsadness\t../data/wav/s20_sadness_F_s15.wav\n",
      "546\tanger\t../data/wav/s5_anger_M_a16.wav\n",
      "547\tneutral\t../data/wav/s8_neutral_M_n20.wav\n",
      "548\thappiness\t../data/wav/s9_happiness_M_h14.wav\n",
      "549\thappiness\t../data/wav/s15_happiness_F_h6.wav\n",
      "550\thappiness\t../data/wav/s13_happiness_F_h12.wav\n",
      "551\tsadness\t../data/wav/s10_sadness_M_s13.wav\n",
      "552\tsadness\t../data/wav/s10_sadness_M_s6.wav\n",
      "553\tneutral\t../data/wav/s18_neutral_F_n9.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\thappiness\t../data/wav/s15_happiness_F_h13.wav\n",
      "559\thappiness\t../data/wav/s3_happiness_M_h1.wav\n",
      "560\tsadness\t../data/wav/s9_sadness_M_s19.wav\n",
      "561\tneutral\t../data/wav/s12_neutral_F_n8.wav\n",
      "563\tsadness\t../data/wav/s2_sadness_M_s18.wav\n",
      "564\thappiness\t../data/wav/s9_happiness_M_h16.wav\n",
      "565\tanger\t../data/wav/s9_anger_M_a11.wav\n",
      "566\tneutral\t../data/wav/s3_neutral_M_n16.wav\n",
      "567\tanger\t../data/wav/s19_anger_M_a19.wav\n",
      "568\tsadness\t../data/wav/s13_sadness_F_s5.wav\n",
      "569\tsadness\t../data/wav/s13_sadness_F_s12.wav\n",
      "574\tsadness\t../data/wav/s18_sadness_F_s17.wav\n",
      "576\tneutral\t../data/wav/s14_neutral_M_n14.wav\n",
      "577\thappiness\t../data/wav/s9_happiness_M_h4.wav\n",
      "580\tneutral\t../data/wav/s3_neutral_M_n8.wav\n",
      "582\thappiness\t../data/wav/s12_happiness_F_h12.wav\n",
      "583\tsadness\t../data/wav/s10_sadness_M_s17.wav\n",
      "585\tsadness\t../data/wav/s19_sadness_M_s2.wav\n",
      "586\tsadness\t../data/wav/s17_sadness_M_s16.wav\n",
      "588\tanger\t../data/wav/s18_anger_F_a16.wav\n",
      "589\tsadness\t../data/wav/s4_sadness_M_s14.wav\n",
      "590\thappiness\t../data/wav/s19_happiness_M_h16.wav\n",
      "591\tanger\t../data/wav/s15_anger_F_a14.wav\n",
      "592\tsadness\t../data/wav/s13_sadness_F_s17.wav\n",
      "594\tsadness\t../data/wav/s9_sadness_M_s18.wav\n",
      "595\tsadness\t../data/wav/s20_sadness_F_s6.wav\n",
      "596\tanger\t../data/wav/s12_anger_F_a2.wav\n",
      "598\tneutral\t../data/wav/s9_neutral_M_n18.wav\n",
      "599\tsadness\t../data/wav/s10_sadness_M_s14.wav\n",
      "603\tanger\t../data/wav/s19_anger_M_a7.wav\n",
      "604\tanger\t../data/wav/s12_anger_F_a5.wav\n",
      "605\tneutral\t../data/wav/s19_neutral_M_n10.wav\n",
      "606\thappiness\t../data/wav/s3_happiness_M_h15.wav\n",
      "607\tsadness\t../data/wav/s20_sadness_F_s11.wav\n",
      "609\tanger\t../data/wav/s14_anger_M_a4.wav\n",
      "610\thappiness\t../data/wav/s15_happiness_F_h8.wav\n",
      "611\tsadness\t../data/wav/s19_sadness_M_s7.wav\n",
      "613\tsadness\t../data/wav/s14_sadness_M_s16.wav\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "Training_vector = []\n",
    "Training_label = []\n",
    "\n",
    "for ix in range(len(Training_filename)):\n",
    "    # 파일 읽어오기\n",
    "    if Training_emotionlist[ix] == \"excitement\":\n",
    "        continue\n",
    "        \n",
    "    if Training_emotionlist[ix] == \"fear\":\n",
    "        continue\n",
    "        \n",
    "    print (str(ix)+ \"\\t\" + Training_emotionlist[ix] + \"\\t\" + path+'wav/' + Training_filename[ix])\n",
    "    \n",
    "    y,sr = utils.loadwav(path+'wav/' + Training_filename[ix])\n",
    "    \n",
    "    temp = emotion.index(Training_emotionlist[ix])    \n",
    "    label = np.zeros(class_size)\n",
    "    label[temp] = 1\n",
    "    \n",
    "    #파일 전체 길이\n",
    "    length = len(y)\n",
    "    \n",
    "    idx = 0\n",
    "    while(idx != length):\n",
    "        #voice 구간 구하기\n",
    "        IAV_th = utils.get_IAV_threshold(y,length,frame_size)\n",
    "        th = IAV_th/frame_size*2\n",
    "        \n",
    "        start_point, end_point = utils.search_voicearea(y,frame_size,length,idx,th,IAV_th)\n",
    "        \n",
    "        if(start_point == -1):\n",
    "            break\n",
    "            \n",
    "        idx = end_point\n",
    "        \n",
    "        segment_length = end_point-start_point+1\n",
    "        \n",
    "        # 세그먼트 추출\n",
    "        segment_list = []\n",
    "        for i in range(start_point,(end_point-window_size), int(window_size/overlap_facor) ):\n",
    "            y_sub = y[i:i+window_size]\n",
    "            \n",
    "            #Normalization\n",
    "            y_sub = y_sub * 2 / math.pow(2,16)\n",
    "            segment_list.append(y_sub)\n",
    "        \n",
    "        if len(segment_list) < time_step:\n",
    "            continue\n",
    "        \n",
    "        for i in range(0, len(segment_list) - time_step+1, 30):\n",
    "            temp = segment_list[i:i+time_step]\n",
    "            Training_vector.append(temp)\n",
    "            Training_label.append(label)\n",
    "            \n",
    "X_train = np.array(Training_vector)\n",
    "Y_train = np.array(Training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1522, 32, 1000) (1522, 4)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(X_train),np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test_vector = []\n",
    "Test_label = []\n",
    "\n",
    "for ix in range(len(Test_filename)):\n",
    "    # 파일 읽어오기\n",
    "    if Test_emotionlist[ix] == \"excitement\":\n",
    "        continue\n",
    "        \n",
    "    if Test_emotionlist[ix] == \"fear\":\n",
    "        continue\n",
    "        \n",
    "    #print (str(ix)+ \"\\t\" + Test_emotionlist[ix] + \"\\t\" + path+'wav/' + Test_filename[ix])\n",
    "    \n",
    "    y,sr = utils.loadwav(path+'wav/' + Test_filename[ix])\n",
    "    \n",
    "    temp = emotion.index(Test_emotionlist[ix])    \n",
    "    label = np.zeros(class_size)\n",
    "    label[temp] = 1\n",
    "    \n",
    "    #파일 전체 길이\n",
    "    length = len(y)\n",
    "    \n",
    "    idx = 0\n",
    "    while(idx != length):\n",
    "        #voice 구간 구하기\n",
    "        IAV_th = utils.get_IAV_threshold(y,length,frame_size)\n",
    "        th = IAV_th/frame_size*2\n",
    "        \n",
    "        start_point, end_point = utils.search_voicearea(y,frame_size,length,idx,th,IAV_th)\n",
    "        \n",
    "        if(start_point == -1):\n",
    "            break\n",
    "            \n",
    "        idx = end_point\n",
    "        \n",
    "        segment_length = end_point-start_point+1\n",
    "        \n",
    "        # 세그먼트 추출\n",
    "        segment_list = []\n",
    "        for i in range(start_point,(end_point-window_size), int(window_size/overlap_facor) ):\n",
    "            y_sub = y[i:i+window_size]\n",
    "            \n",
    "            #Normalization\n",
    "            y_sub = y_sub * 2 / math.pow(2,16)\n",
    "            segment_list.append(y_sub)\n",
    "        \n",
    "        if len(segment_list) < time_step:\n",
    "            continue\n",
    "        \n",
    "        for i in range(0, len(segment_list) - time_step+1, 30):\n",
    "            temp = segment_list[i:i+time_step]\n",
    "            Test_vector.append(temp)\n",
    "            Test_label.append(label)\n",
    "            \n",
    "X_test = np.array(Test_vector)\n",
    "Y_test = np.array(Test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 32, 1000) (593, 4)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(X_test),np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train,3)\n",
    "X_test = np.expand_dims(X_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.arange(np.shape(X_train)[0])\n",
    "np.random.shuffle(random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[random_index]\n",
    "Y_train = Y_train[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1522, 32, 1000, 1) (593, 32, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(X_train), np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1522, 4) (593, 4)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(Y_train), np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter 1 initialize\n",
    "filters1 = 100\n",
    "kernel_size1 = 10\n",
    "stride1 = 1\n",
    "#Filter 2 initialize\n",
    "filters2 = 160\n",
    "kernel_size2 = 10\n",
    "stride2 = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, time_step, window_size,1])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, class_size])\n",
    "\n",
    "filter1 = tf.Variable(tf.random_normal([kernel_size1,1,filters1], stddev= 0.01))\n",
    "filter2 = tf.Variable(tf.random_normal([kernel_size1,filters1,filters1], stddev= 0.01))\n",
    "\n",
    "filter3 = tf.Variable(tf.random_normal([kernel_size2,filters1,filters2], stddev= 0.01))\n",
    "filter4 = tf.Variable(tf.random_normal([kernel_size2,filters2,filters2], stddev= 0.01))\n",
    "\n",
    "stack = []\n",
    "for i in range(time_step):\n",
    "    conv_layer1 = tf.nn.relu(tf.nn.conv1d(X[:,i,:,:], filter1, stride1, 'VALID'))\n",
    "    conv_layer2 = tf.nn.relu(tf.nn.conv1d(conv_layer1, filter2, stride2, 'VALID'))\n",
    "    pooling_layer1 = tf.nn.pool(conv_layer2,[3],'MAX','SAME',strides = [3])\n",
    "    \n",
    "    conv_layer3 = tf.nn.relu(tf.nn.conv1d(pooling_layer1, filter3, stride2, 'VALID'))\n",
    "    conv_layer4 = tf.nn.relu(tf.nn.conv1d(conv_layer3, filter4, stride2, 'VALID'))\n",
    "    GAP_layer = layers.GlobalAveragePooling1D()(conv_layer4)\n",
    "    #dropout = layers.Dropout(0.5)(GAP_layer)\n",
    "    \n",
    "    #conv_layer1 = tf.nn.relu(tf.nn.conv1d(X[:,i,:,:], filter1, stride1, 'VALID'))\n",
    "    #conv_layer2 = tf.nn.relu(tf.nn.conv1d(conv_layer1, filter2, stride1, 'VALID'))\n",
    "    #pooling_layer1 = tf.nn.pool(conv_layer2,[3],'MAX','SAME',strides = [3])\n",
    "    #conv_layer3 = tf.nn.relu(tf.nn.conv1d(pooling_layer1, filter3, stride2, 'VALID'))\n",
    "    #conv_layer4 = tf.nn.relu(tf.nn.conv1d(conv_layer3, filter4, stride2, 'VALID'))\n",
    "    \n",
    "    #GAP_layer = layers.GlobalAveragePooling1D()(conv_layer4)\n",
    "    #dropout = tf.nn.dropout(GAP_layer, keep_prob = 0.5)\n",
    "    \n",
    "    stack.append(GAP_layer)\n",
    "    \n",
    "LSTM_input = tf.stack(stack, axis = 1)\n",
    "\n",
    "LSTM1 = layers.LSTM(32, dropout=0.5, recurrent_dropout = 0.5, input_shape = (time_step, feature_size))(LSTM_input)\n",
    "\n",
    "#LSTM1 = layers.LSTM(64, dropout=0.5, recurrent_dropout = 0.5, return_sequences = True, input_shape = (time_step, feature_size))(LSTM_input)\n",
    "#LSTM2 = layers.LSTM(32, dropout=0.5, recurrent_dropout = 0.5 )(LSTM1)\n",
    "Dense1 = layers.Dense(100, kernel_regularizer= regularizers.l2(0.001), activation='relu')(LSTM1)\n",
    "dropout2 = layers.Dropout(0.5)(Dense1)\n",
    "\n",
    "hypothesis = layers.Dense(class_size, activation='softmax')(dropout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(categorical_crossentropy(Y, hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, _X,_Y):\n",
    "        self.X = _X\n",
    "        self.Y = _Y\n",
    "        self.cursor = 0\n",
    "        self.length = len(_X)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        flag = False\n",
    "        \n",
    "        if self.cursor + batch_size >= self.length:\n",
    "            self.cursor = self.length - batch_size\n",
    "            flag = True\n",
    "            \n",
    "        batch_x = self.X[self.cursor:self.cursor+batch_size]\n",
    "        batch_y = self.Y[self.cursor:self.cursor+batch_size]\n",
    "        \n",
    "        if flag == True:\n",
    "            self.cursor = 0\n",
    "        else:\n",
    "            self.cursor = self.cursor + batch_size\n",
    "        \n",
    "        return (batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0/100]: loss = 1.230123\ttrain accuracy : 0.425806\ttest loss = 1.180839\ttest accuracy : 0.516667\n",
      "\n",
      "[epoch 1/100]: loss = 1.111567\ttrain accuracy : 0.483871\ttest loss = 1.128577\ttest accuracy : 0.548333\n",
      "\n",
      "[epoch 2/100]: loss = 1.043717\ttrain accuracy : 0.518065\ttest loss = 1.152420\ttest accuracy : 0.546667\n",
      "\n",
      "[epoch 3/100]: loss = 0.998596\ttrain accuracy : 0.541935\ttest loss = 1.113705\ttest accuracy : 0.591667\n",
      "\n",
      "[epoch 4/100]: loss = 0.952428\ttrain accuracy : 0.558710\ttest loss = 1.038630\ttest accuracy : 0.435000\n",
      "\n",
      "[epoch 5/100]: loss = 0.897929\ttrain accuracy : 0.577419\ttest loss = 1.068841\ttest accuracy : 0.550000\n",
      "\n",
      "[epoch 6/100]: loss = 0.862295\ttrain accuracy : 0.586452\ttest loss = 0.980873\ttest accuracy : 0.576667\n",
      "\n",
      "[epoch 7/100]: loss = 0.787217\ttrain accuracy : 0.641935\ttest loss = 1.071977\ttest accuracy : 0.580000\n",
      "\n",
      "[epoch 8/100]: loss = 0.796642\ttrain accuracy : 0.618710\ttest loss = 0.966589\ttest accuracy : 0.605000\n",
      "\n",
      "[epoch 9/100]: loss = 0.721683\ttrain accuracy : 0.669677\ttest loss = 0.973339\ttest accuracy : 0.611667\n",
      "\n",
      "[epoch 10/100]: loss = 0.732796\ttrain accuracy : 0.671613\ttest loss = 0.979069\ttest accuracy : 0.585000\n",
      "\n",
      "[epoch 11/100]: loss = 0.660069\ttrain accuracy : 0.716774\ttest loss = 0.896035\ttest accuracy : 0.656667\n",
      "\n",
      "[epoch 12/100]: loss = 0.662129\ttrain accuracy : 0.709677\ttest loss = 0.930124\ttest accuracy : 0.605000\n",
      "\n",
      "[epoch 13/100]: loss = 0.693342\ttrain accuracy : 0.698710\ttest loss = 0.940959\ttest accuracy : 0.633333\n",
      "\n",
      "[epoch 14/100]: loss = 0.577747\ttrain accuracy : 0.750323\ttest loss = 0.974403\ttest accuracy : 0.633333\n",
      "\n",
      "[epoch 15/100]: loss = 0.609881\ttrain accuracy : 0.746452\ttest loss = 0.888157\ttest accuracy : 0.686667\n",
      "\n",
      "[epoch 16/100]: loss = 0.573456\ttrain accuracy : 0.742581\ttest loss = 0.884621\ttest accuracy : 0.681667\n",
      "\n",
      "[epoch 17/100]: loss = 0.487834\ttrain accuracy : 0.795484\ttest loss = 1.078528\ttest accuracy : 0.606667\n",
      "\n",
      "[epoch 18/100]: loss = 0.491092\ttrain accuracy : 0.783871\ttest loss = 0.962982\ttest accuracy : 0.643333\n",
      "\n",
      "[epoch 19/100]: loss = 0.501279\ttrain accuracy : 0.776129\ttest loss = 1.013648\ttest accuracy : 0.651667\n",
      "\n",
      "[epoch 20/100]: loss = 0.553033\ttrain accuracy : 0.758710\ttest loss = 0.902171\ttest accuracy : 0.676667\n",
      "\n",
      "[epoch 21/100]: loss = 0.450836\ttrain accuracy : 0.818710\ttest loss = 0.979774\ttest accuracy : 0.661667\n",
      "\n",
      "[epoch 22/100]: loss = 0.492920\ttrain accuracy : 0.796129\ttest loss = 0.970059\ttest accuracy : 0.681667\n",
      "\n",
      "[epoch 23/100]: loss = 0.424555\ttrain accuracy : 0.820000\ttest loss = 0.957384\ttest accuracy : 0.681667\n",
      "\n",
      "[epoch 24/100]: loss = 0.417813\ttrain accuracy : 0.825161\ttest loss = 0.881711\ttest accuracy : 0.680000\n",
      "\n",
      "[epoch 25/100]: loss = 0.429485\ttrain accuracy : 0.818710\ttest loss = 0.911060\ttest accuracy : 0.676667\n",
      "\n",
      "[epoch 26/100]: loss = 0.473577\ttrain accuracy : 0.796774\ttest loss = 0.894255\ttest accuracy : 0.701667\n",
      "\n",
      "[epoch 27/100]: loss = 0.468821\ttrain accuracy : 0.803226\ttest loss = 0.887881\ttest accuracy : 0.650000\n",
      "\n",
      "[epoch 28/100]: loss = 0.415792\ttrain accuracy : 0.830968\ttest loss = 1.018416\ttest accuracy : 0.620000\n",
      "\n",
      "[epoch 29/100]: loss = 0.411703\ttrain accuracy : 0.832258\ttest loss = 0.868828\ttest accuracy : 0.675000\n",
      "\n",
      "[epoch 30/100]: loss = 0.361257\ttrain accuracy : 0.857419\ttest loss = 0.929622\ttest accuracy : 0.663333\n",
      "\n",
      "[epoch 31/100]: loss = 0.331094\ttrain accuracy : 0.856774\ttest loss = 1.006264\ttest accuracy : 0.631667\n",
      "\n",
      "[epoch 32/100]: loss = 0.310751\ttrain accuracy : 0.880000\ttest loss = 1.031281\ttest accuracy : 0.675000\n",
      "\n",
      "[epoch 33/100]: loss = 0.308513\ttrain accuracy : 0.880645\ttest loss = 1.045381\ttest accuracy : 0.646667\n",
      "\n",
      "[epoch 34/100]: loss = 0.319047\ttrain accuracy : 0.869677\ttest loss = 1.227332\ttest accuracy : 0.611667\n",
      "\n",
      "[epoch 35/100]: loss = 0.347801\ttrain accuracy : 0.851613\ttest loss = 1.188638\ttest accuracy : 0.631667\n",
      "\n",
      "[epoch 36/100]: loss = 0.340030\ttrain accuracy : 0.862581\ttest loss = 1.032929\ttest accuracy : 0.686667\n",
      "\n",
      "[epoch 37/100]: loss = 0.251321\ttrain accuracy : 0.896774\ttest loss = 1.217858\ttest accuracy : 0.640000\n",
      "\n",
      "[epoch 38/100]: loss = 0.267555\ttrain accuracy : 0.901290\ttest loss = 1.114932\ttest accuracy : 0.655000\n",
      "\n",
      "[epoch 39/100]: loss = 0.275858\ttrain accuracy : 0.890968\ttest loss = 1.167243\ttest accuracy : 0.686667\n",
      "\n",
      "[epoch 40/100]: loss = 0.257666\ttrain accuracy : 0.896774\ttest loss = 1.124439\ttest accuracy : 0.688333\n",
      "\n",
      "[epoch 41/100]: loss = 0.257790\ttrain accuracy : 0.896129\ttest loss = 1.223362\ttest accuracy : 0.685000\n",
      "\n",
      "[epoch 42/100]: loss = 0.215082\ttrain accuracy : 0.914194\ttest loss = 1.242668\ttest accuracy : 0.671667\n",
      "\n",
      "[epoch 43/100]: loss = 0.150180\ttrain accuracy : 0.937419\ttest loss = 1.267114\ttest accuracy : 0.678333\n",
      "\n",
      "[epoch 44/100]: loss = 0.129529\ttrain accuracy : 0.950968\ttest loss = 1.314086\ttest accuracy : 0.680000\n",
      "\n",
      "[epoch 45/100]: loss = 0.108845\ttrain accuracy : 0.961290\ttest loss = 1.605870\ttest accuracy : 0.671667\n",
      "\n",
      "[epoch 46/100]: loss = 0.133050\ttrain accuracy : 0.952258\ttest loss = 1.670553\ttest accuracy : 0.645000\n",
      "\n",
      "[epoch 47/100]: loss = 0.178850\ttrain accuracy : 0.933548\ttest loss = 1.319784\ttest accuracy : 0.670000\n",
      "\n",
      "[epoch 48/100]: loss = 0.265142\ttrain accuracy : 0.897419\ttest loss = 1.226866\ttest accuracy : 0.666667\n",
      "\n",
      "[epoch 49/100]: loss = 0.196273\ttrain accuracy : 0.921935\ttest loss = 1.517798\ttest accuracy : 0.670000\n",
      "\n",
      "[epoch 50/100]: loss = 0.130862\ttrain accuracy : 0.952903\ttest loss = 1.496583\ttest accuracy : 0.676667\n",
      "\n",
      "[epoch 51/100]: loss = 0.173702\ttrain accuracy : 0.936774\ttest loss = 1.351631\ttest accuracy : 0.690000\n",
      "\n",
      "[epoch 52/100]: loss = 0.284525\ttrain accuracy : 0.900000\ttest loss = 1.284381\ttest accuracy : 0.670000\n",
      "\n",
      "[epoch 53/100]: loss = 0.354130\ttrain accuracy : 0.854839\ttest loss = 1.158986\ttest accuracy : 0.665000\n",
      "\n",
      "[1500/1522] : 0.99 % \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8c179ec1d87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestBatchGen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0macc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mavg_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "epochs = 100\n",
    "batch_size = 50\n",
    "train_len = len(X_train)\n",
    "test_len = len(X_test)\n",
    "\n",
    "TrainBatchGen = BatchGenerator(X_train,Y_train)\n",
    "TestBatchGen = BatchGenerator(X_test,Y_test)\n",
    "\n",
    "train_loss = np.zeros(epochs)\n",
    "train_acc = np.zeros(epochs)\n",
    "test_loss = np.zeros(epochs)\n",
    "test_acc = np.zeros(epochs)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        avg_loss = 0.\n",
    "        avg_acc = 0.\n",
    "        cnt = 0\n",
    "        for i in range(0,train_len,batch_size):\n",
    "            batch_x, batch_y = TrainBatchGen.next_batch(batch_size)\n",
    "            \n",
    "            print (\"[%d/%d] : %.2f %% \"%(i,train_len, i/train_len), end = \"\\r\")\n",
    "            \n",
    "            sess.run(train, feed_dict = {X: batch_x, Y: batch_y})\n",
    "            loss_ = sess.run(loss, feed_dict= {X:batch_x, Y: batch_y})\n",
    "            acc_ = sess.run(accuracy, feed_dict= {X:batch_x, Y: batch_y})\n",
    "            \n",
    "            avg_loss += loss_\n",
    "            avg_acc += acc_\n",
    "            cnt += 1\n",
    "            \n",
    "        avg_loss = avg_loss / cnt\n",
    "        avg_acc = avg_acc / cnt\n",
    "        \n",
    "        train_loss[epoch] = avg_loss\n",
    "        train_acc[epoch] = avg_acc\n",
    "        \n",
    "        avg_loss = 0.\n",
    "        avg_acc = 0.        \n",
    "        cnt = 0\n",
    "        for i in range(0,test_len,batch_size):\n",
    "            batch_x, batch_y = TestBatchGen.next_batch(batch_size)\n",
    "            acc_ = sess.run(accuracy, feed_dict= {X:batch_x, Y: batch_y})\n",
    "            loss_ = sess.run(loss, feed_dict= {X:batch_x, Y: batch_y})\n",
    "            \n",
    "            avg_acc += acc_\n",
    "            avg_loss += loss_\n",
    "            cnt +=1\n",
    "        \n",
    "        avg_loss = avg_loss / cnt\n",
    "        avg_acc = avg_acc / cnt\n",
    "        \n",
    "        test_loss[epoch] = avg_loss\n",
    "        test_acc[epoch] = avg_acc\n",
    "        \n",
    "        print(\"[epoch %d/%d]: loss = %f\\ttrain accuracy : %f\\ttest loss = %f\\ttest accuracy : %f\\n\" % \n",
    "              (epoch,epochs, train_loss[epoch], train_acc[epoch], test_loss[epoch], test_acc[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
